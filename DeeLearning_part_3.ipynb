{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNKFN/LMEG6mTOTerX/B+TV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/captain7oxic/Pytorch_practice/blob/main/DeeLearning_part_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook we will try to calculate loss as well as implement back-propogation of a neural network using pytorch."
      ],
      "metadata": {
        "id": "f5Vjqy9Par6y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -c https://raw.githubusercontent.com/udacity/deep-learning-v2-pytorch/master/intro-to-pytorch/helper.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtRfocIFAO_7",
        "outputId": "e5a03207-231d-4ea8-9c20-e936f456bdaf"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-16 07:00:31--  https://raw.githubusercontent.com/udacity/deep-learning-v2-pytorch/master/intro-to-pytorch/helper.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 416 Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importing the data\n",
        "from six.moves import urllib\n",
        "opener = urllib.request.build_opener()\n",
        "opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
        "urllib.request.install_opener(opener)"
      ],
      "metadata": {
        "id": "4P34btx2a7a1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms"
      ],
      "metadata": {
        "id": "jqrHN3WfbuTU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define a Transform to Normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5),(0.5)),])"
      ],
      "metadata": {
        "id": "br6CPzt5bzH9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#collecting all the data and running the normalization on entire data\n",
        "trainset = datasets.MNIST('~/.pytorch/MNIST_data/',download=True,train=True,transform = transform)"
      ],
      "metadata": {
        "id": "v4nGomplcuvd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#defining the batchsize and shuffling the data in the loader\n",
        "loader  = torch.utils.data.DataLoader(trainset,batch_size = 64,shuffle = True)"
      ],
      "metadata": {
        "id": "b79AiprbcoQF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating a feed-forward Neural Network\n",
        "\n",
        "Net = nn.Sequential(\n",
        "    nn.Linear(784,128),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(128,64),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(64,10)\n",
        ")"
      ],
      "metadata": {
        "id": "RKbSkMvJfe8Q"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define our loss\n",
        "loss = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "24zDIAFJgqAJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are many loss functions\n",
        "(1)**Regression Loss Functions**\n",
        "Mean Squared Error Loss\n",
        "\n",
        "Mean Squared Logarithmic Error Loss\n",
        "\n",
        "Mean Absolute Error Loss *italicized text*\n",
        "\n",
        "(2)**Binary Classification Loss Functions**\n",
        "\n",
        "Binary Cross-Entropy\n",
        "\n",
        "Hinge Loss\n",
        "\n",
        "Squared Hinge Loss *italicized text*\n",
        "\n",
        "(3)**Multi-Class Classification Loss Functions**\n",
        "\n",
        "Multi-Class Cross-Entropy Loss\n",
        "\n",
        "Sparse Multiclass Cross-Entropy Loss\n",
        "\n",
        "Kullback Leibler Divergence Loss *italicized text*"
      ],
      "metadata": {
        "id": "NUJS20A7hkDa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#iterate over the data\n",
        "data_iter = iter(loader)\n",
        "\n",
        "images,labels = next(data_iter)"
      ],
      "metadata": {
        "id": "7yjyHKqthE6b"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#flatten the images\n",
        "images = images.view(images.shape[0],-1)"
      ],
      "metadata": {
        "id": "rOmjegF-jmF3"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Forward pass, get our logits\n",
        "logits = Net(images)"
      ],
      "metadata": {
        "id": "TGJVKnXblSwk"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_loss=loss(logits,labels)\n",
        "print(total_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxyyJilSlTsr",
        "outputId": "5cf27abb-1cd7-4166-bfde-6f995596c078"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.3001, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise: Build a model that returns the log-softmax as the output and calculate the loss using the negative log likelihood loss. Note that for nn.LogSoftmax and F.log_softmax you'll need to set the dim keyword argument appropriately. dim=0 calculates softmax across the rows, so each column sums to 1, while dim=1 calculates across the columns so each row sums to 1. Think about what you want the output to be and choose dim appropriately."
      ],
      "metadata": {
        "id": "ovkiYRIKvBNU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.modules.activation import LogSoftmax\n",
        "# TODO: Build a feed-forward network\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(784,128),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(128,64),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(64,10),\n",
        "    nn.LogSoftmax(dim=1)\n",
        ")\n",
        "\n",
        "# TODO: Define the loss\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "### Run this to check your work\n",
        "# Get our data\n",
        "dataiter = iter(loader)\n",
        "\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# Flatten images\n",
        "images = images.view(images.shape[0], -1)\n",
        "\n",
        "# Forward pass, get our logits\n",
        "logits = model(images)\n",
        "# Calculate the loss with the logits and the labels\n",
        "loss = criterion(logits, labels)\n",
        "\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MeMbz5rUp98W",
        "outputId": "5b195694-8e63-4f8c-ae45-0a9b76963ac1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.3188, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "clearly the loss is reduced in this example , now we will try to use AutoGrad . Autograd typically stores the trace of calculations happening over the tensor , which helps to make the chained derivatives calculations faster."
      ],
      "metadata": {
        "id": "suw2y7mav23_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(2,2, requires_grad=True)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MSht5nJvvuF",
        "outputId": "5709f78d-8283-4ea6-a1b4-73443b8f60ce"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.2801,  0.0701],\n",
            "        [ 0.4115, -0.7776]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = x**2\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7-jupNFwmBe",
        "outputId": "f296e6cc-3561-406c-c065-7e0f003bbcb2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0784, 0.0049],\n",
            "        [0.1693, 0.6047]], grad_fn=<PowBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## grad_fn shows the function that generated this variable\n",
        "print(y.grad_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRsauPRHwqVD",
        "outputId": "e50f3712-c93e-4633-97be-2232318c6320"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<PowBackward0 object at 0x7f4fc0d08250>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z= y.mean()"
      ],
      "metadata": {
        "id": "YNTiY5X0wtb3"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z.backward()\n",
        "print(x.grad)\n",
        "print(x/2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MW4JAnTS7CaR",
        "outputId": "2ba93ba3-d342-48ab-c567-4311a5cfa135"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.1400,  0.0350],\n",
            "        [ 0.2058, -0.3888]])\n",
            "tensor([[-0.1400,  0.0350],\n",
            "        [ 0.2058, -0.3888]], grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#now lets use Autograd and Loss functions together"
      ],
      "metadata": {
        "id": "wBDesiCy7DTe"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Linear(784,128),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(128,64),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(64,10),\n",
        "    nn.LogSoftmax(dim=1)\n",
        ")\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "dataiter = iter(loader)\n",
        "images, labels = next(dataiter)\n",
        "images = images.view(images.shape[0], -1)\n",
        "\n",
        "logits = model(images)\n",
        "loss = criterion(logits,labels)"
      ],
      "metadata": {
        "id": "cTvfheJm8Lc7"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8LHOU0V858_",
        "outputId": "db92676c-61ce-45c3-fc74-dc4e38184c39"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.3036, grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Before backward pass: \\n', model[0].weight.grad)\n",
        "\n",
        "loss.backward()\n",
        "\n",
        "print('After backward pass: \\n', model[0].weight.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPi3kZKR9lbp",
        "outputId": "3a91db5c-a3ae-441b-bc29-d18213edc9cb"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before backward pass: \n",
            " None\n",
            "After backward pass: \n",
            " tensor([[-0.0018, -0.0018, -0.0018,  ..., -0.0018, -0.0018, -0.0018],\n",
            "        [-0.0004, -0.0004, -0.0004,  ..., -0.0004, -0.0004, -0.0004],\n",
            "        [ 0.0030,  0.0030,  0.0030,  ...,  0.0030,  0.0030,  0.0030],\n",
            "        ...,\n",
            "        [-0.0003, -0.0003, -0.0003,  ..., -0.0003, -0.0003, -0.0003],\n",
            "        [ 0.0016,  0.0016,  0.0016,  ...,  0.0016,  0.0016,  0.0016],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For The garnish we have the Optim package of the pytorch library to enable Gradient descent calculations on the network."
      ],
      "metadata": {
        "id": "Q9ZW5fYW_ZOU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import optim"
      ],
      "metadata": {
        "id": "ekX3hvCm9tV8"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "sIW5GMZN_oCZ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Initial weights - ', model[0].weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onM3bNcV_vKD",
        "outputId": "da9b3e30-dbd4-4d43-b4e3-c4de955c25f0"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial weights -  Parameter containing:\n",
            "tensor([[ 0.0179,  0.0143,  0.0338,  ..., -0.0165, -0.0240,  0.0092],\n",
            "        [ 0.0103, -0.0148,  0.0197,  ..., -0.0108,  0.0155, -0.0209],\n",
            "        [-0.0139,  0.0081,  0.0344,  ..., -0.0253, -0.0107, -0.0061],\n",
            "        ...,\n",
            "        [ 0.0210, -0.0138,  0.0352,  ...,  0.0061,  0.0063,  0.0173],\n",
            "        [ 0.0147, -0.0035,  0.0229,  ..., -0.0002,  0.0223, -0.0139],\n",
            "        [ 0.0285,  0.0159, -0.0350,  ...,  0.0329, -0.0131, -0.0216]],\n",
            "       requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(loader)\n",
        "images,labels = next(dataiter)\n",
        "images = images.resize(64,784)\n",
        "\n",
        "\n",
        "# Clear the gradients, do this because gradients are accumulated\n",
        "optimizer.zero_grad()\n",
        "\n",
        "output =  model(images)\n",
        "loss = criterion(output,labels)\n",
        "loss.backward()\n",
        "print('gradient - ', model[0].weight.grad)"
      ],
      "metadata": {
        "id": "ESD3CbYE_yAJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96a3f9b0-ec68-4710-ddaa-8f31dd9538eb"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gradient -  tensor([[-0.0015, -0.0015, -0.0015,  ..., -0.0015, -0.0015, -0.0015],\n",
            "        [-0.0010, -0.0010, -0.0010,  ..., -0.0010, -0.0010, -0.0010],\n",
            "        [ 0.0022,  0.0022,  0.0022,  ...,  0.0022,  0.0022,  0.0022],\n",
            "        ...,\n",
            "        [-0.0010, -0.0010, -0.0010,  ..., -0.0010, -0.0010, -0.0010],\n",
            "        [ 0.0006,  0.0006,  0.0006,  ...,  0.0006,  0.0006,  0.0006],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/_tensor.py:775: UserWarning: non-inplace resize is deprecated\n",
            "  warnings.warn(\"non-inplace resize is deprecated\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Take an update step and view the new weights\n",
        "optimizer.step()\n",
        "print('Updated weights - ', model[0].weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TS_GBFZrxirm",
        "outputId": "b8703d16-d968-47a6-8463-24220671d9d2"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated weights -  Parameter containing:\n",
            "tensor([[ 0.0179,  0.0143,  0.0338,  ..., -0.0165, -0.0240,  0.0092],\n",
            "        [ 0.0103, -0.0148,  0.0197,  ..., -0.0108,  0.0155, -0.0209],\n",
            "        [-0.0139,  0.0081,  0.0344,  ..., -0.0254, -0.0108, -0.0061],\n",
            "        ...,\n",
            "        [ 0.0210, -0.0138,  0.0352,  ...,  0.0061,  0.0063,  0.0173],\n",
            "        [ 0.0147, -0.0035,  0.0229,  ..., -0.0002,  0.0223, -0.0139],\n",
            "        [ 0.0285,  0.0159, -0.0350,  ...,  0.0329, -0.0131, -0.0216]],\n",
            "       requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement the training pass for our network. If you implemented it correctly, you should see the training loss drop with each epoch."
      ],
      "metadata": {
        "id": "3DGZro5N6dyp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Linear(784,128),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(128,64),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(64,10),\n",
        "    nn.LogSoftmax(dim=1))\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(),lr=0.3)\n",
        "epochs = 5\n",
        "\n",
        "for e in range(epochs):\n",
        "  running_loss = 0\n",
        "  for images,labels in loader:\n",
        "  #flatten\n",
        "    images = images.view(images.shape[0],-1)\n",
        "\n",
        "    #remove accumulated gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "\n",
        "    #loss\n",
        "    output = model(images)\n",
        "    loss= criterion(output,labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    running_loss+=loss.item()\n",
        "  else:\n",
        "          print(f\"Training loss: {running_loss/len(loader)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38AT2ff0yCiF",
        "outputId": "b7b10fa3-54db-45fd-d657-4a6edabfa12d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 1.8224720779512482\n",
            "Training loss: 0.9748743534850668\n",
            "Training loss: 0.6002745570054949\n",
            "Training loss: 0.5268741858634614\n",
            "Training loss: 0.6233894656747897\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import helper\n",
        "\n",
        "images, labels = next(iter(loader))\n",
        "\n",
        "img = images[0].view(1, 784)\n",
        "# Turn off gradients to speed up this part\n",
        "with torch.no_grad():\n",
        "    logps = model(img)\n",
        "\n",
        "# Output of the network are log-probabilities, need to take exponential for probabilities\n",
        "ps = torch.exp(logps)\n",
        "helper.view_classify(img.view(1, 28, 28), ps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "H9PwoPke9h3N",
        "outputId": "edfb4bf1-0d09-4aa9-9887-03e79f7c50b8"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x900 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ml6PaQnd_2L3"
      },
      "execution_count": 29,
      "outputs": []
    }
  ]
}